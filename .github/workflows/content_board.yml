name: Content Board (Nightly Digest)

on:
  workflow_dispatch:

  # DST-safe scheduling:
  # - 7pm PT is 03:00 UTC during PST (winter)
  # - 7pm PT is 02:00 UTC during PDT (summer)
  # Run every 10 minutes during BOTH hours; digest.py guard posts only once.
  schedule:
    - cron: "*/10 2,3 * * *"

jobs:
  post_digest:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # ---------
      # AUTO: Fetch latest YouTube upload (no API key)
      # Uses handle page -> extracts channel id (UC...)
      # Then tries RSS:
      #   1) channel_id feed
      #   2) uploads playlist feed (playlist_id=UU... fallback)
      # ---------
      - name: Resolve latest YouTube video (auto)
        env:
          YT_HANDLE_URL: "https://www.youtube.com/@smitty-2447"
          USER_AGENT: "IttyBittyGamingNews/Workflow"
        run: |
          python - << 'PY'
          import os, re, sys
          import xml.etree.ElementTree as ET
          import requests

          handle_url = os.getenv("YT_HANDLE_URL", "").strip()
          ua = os.getenv("USER_AGENT", "IttyBittyGamingNews/Workflow").strip()
          headers = {"User-Agent": ua}

          if not handle_url:
              print("[YT] Missing YT_HANDLE_URL", file=sys.stderr)
              sys.exit(0)

          # 1) Fetch handle page and extract channel id (UC...)
          try:
              r = requests.get(handle_url, headers=headers, timeout=25)
              r.raise_for_status()
              html = r.text
          except Exception as e:
              print(f"[YT] Failed to fetch handle page: {e}", file=sys.stderr)
              sys.exit(0)

          patterns = [
              r'"channelId"\s*:\s*"(?P<id>UC[a-zA-Z0-9_-]{10,})"',
              r'"browseId"\s*:\s*"(?P<id>UC[a-zA-Z0-9_-]{10,})"',
              r'<meta\s+property="og:url"\s+content="https://www\.youtube\.com/channel/(?P<id>UC[a-zA-Z0-9_-]{10,})"',
              r'https://www\.youtube\.com/channel/(?P<id>UC[a-zA-Z0-9_-]{10,})',
          ]

          channel_id = None
          for pat in patterns:
              m = re.search(pat, html)
              if m:
                  channel_id = m.group("id")
                  break

          if not channel_id:
              print("[YT] Could not extract channel id from handle page HTML. Skipping YouTube auto.", file=sys.stderr)
              sys.exit(0)

          print(f"[YT] channel_id={channel_id}")

          # 2) Try RSS endpoints in order
          # A) channel_id feed
          # B) uploads playlist feed (UU... fallback)
          uploads_playlist_id = "UU" + channel_id[2:] if channel_id.startswith("UC") else ""
          rss_candidates = [
              f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}",
          ]
          if uploads_playlist_id:
              rss_candidates.append(f"https://www.youtube.com/feeds/videos.xml?playlist_id={uploads_playlist_id}")

          xml_text = None
          used_rss = None

          for rss_url in rss_candidates:
              try:
                  rr = requests.get(rss_url, headers=headers, timeout=25)
                  if rr.status_code == 404:
                      print(f"[YT] RSS 404 (will try fallback): {rss_url}")
                      continue
                  rr.raise_for_status()
                  xml_text = rr.text
                  used_rss = rss_url
                  break
              except Exception as e:
                  print(f"[YT] RSS fetch failed (will try fallback): {rss_url} -> {e}", file=sys.stderr)

          if not xml_text:
              print("[YT] Could not fetch any RSS feed (channel_id + uploads playlist). Skipping YouTube auto.", file=sys.stderr)
              sys.exit(0)

          print(f"[YT] using_rss={used_rss}")

          # 3) Parse RSS and take first entry
          try:
              root = ET.fromstring(xml_text)
          except Exception as e:
              print(f"[YT] RSS parse failed: {e}", file=sys.stderr)
              sys.exit(0)

          ns = {"a": "http://www.w3.org/2005/Atom"}
          entry = root.find("a:entry", ns)
          if entry is None:
              print("[YT] RSS had no entries. Skipping YouTube auto.", file=sys.stderr)
              sys.exit(0)

          title_el = entry.find("a:title", ns)
          link_el = entry.find("a:link", ns)
          title = (title_el.text or "").strip() if title_el is not None else ""
          href = (link_el.attrib.get("href") or "").strip() if link_el is not None else ""

          if not href:
              print("[YT] RSS entry missing link href. Skipping YouTube auto.", file=sys.stderr)
              sys.exit(0)

          env_path = os.getenv("GITHUB_ENV")
          if not env_path:
              print("[YT] Missing GITHUB_ENV (unexpected).", file=sys.stderr)
              sys.exit(0)

          safe_title = title.replace("\n", " ").replace("\r", " ").strip()

          with open(env_path, "a", encoding="utf-8") as f:
              f.write(f"YOUTUBE_FEATURED_URL={href}\n")
              f.write(f"YOUTUBE_FEATURED_TITLE={safe_title}\n")

          print(f"[YT] latest_url={href}")
          print(f"[YT] latest_title={title}")
          PY

      - name: Run digest
        env:
          # Discord webhook for the forward-facing "content board" channel
          DISCORD_WEBHOOK_URL: ${{ secrets.CONTENT_BOARD_WEBHOOK_URL }}

          # Digest behavior
          DIGEST_WINDOW_HOURS: "24"
          DIGEST_TOP_N: "5"
          DIGEST_MAX_PER_SOURCE: "1"

          # Time guard (7pm PT) + DST handling
          DIGEST_GUARD_TZ: "America/Los_Angeles"
          DIGEST_GUARD_LOCAL_HOUR: "19"
          DIGEST_GUARD_WINDOW_MINUTES: "15"

          # Branding
          NEWSLETTER_NAME: "Itty Bitty Gaming News"
          NEWSLETTER_TAGLINE: "Snackable daily gaming news — five days a week."

          # Featured video section labels
          FEATURED_VIDEO_TITLE: "Watch today’s Itty Bitty Gaming News"
          FEATURED_VIDEO_FALLBACK_URL: "https://adilo.bigcommand.com/c/ittybittygamingnews/home"

          # Adilo API
          ADILO_PUBLIC_KEY: ${{ secrets.ADILO_PUBLIC_KEY }}
          ADILO_SECRET_KEY: ${{ secrets.ADILO_SECRET_KEY }}
          ADILO_PROJECT_ID: "yz8kq5M8"

          # Adilo public pages (scrape fallback)
          ADILO_PUBLIC_LATEST_PAGE: "https://adilo.bigcommand.com/c/ittybittygamingnews/video"
          ADILO_PUBLIC_HOME_PAGE: "https://adilo.bigcommand.com/c/ittybittygamingnews/home"

          # YouTube values are set automatically by the previous step into GITHUB_ENV
          YOUTUBE_FEATURED_URL: ${{ env.YOUTUBE_FEATURED_URL }}
          YOUTUBE_FEATURED_TITLE: ${{ env.YOUTUBE_FEATURED_TITLE }}

          USER_AGENT: "IttyBittyGamingNews/Digest"

        run: |
          python digest.py
