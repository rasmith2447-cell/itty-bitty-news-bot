name: Content Board (Nightly Digest)

on:
  workflow_dispatch:

  # DST-safe scheduling:
  # - 7pm PT is 03:00 UTC during PST (winter)
  # - 7pm PT is 02:00 UTC during PDT (summer)
  # Run every 10 minutes during BOTH hours; digest.py guard posts only once.
  schedule:
    - cron: "*/10 2,3 * * *"

jobs:
  post_digest:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install requests

      # ---------
      # AUTO: Resolve latest YouTube upload by scraping /videos (no API key, no RSS)
      # Then use YouTube oEmbed to get the title cleanly.
      # ---------
      - name: Resolve latest YouTube video (scrape)
        env:
          YT_VIDEOS_URL: "https://www.youtube.com/@smitty-2447/videos"
          USER_AGENT: "Mozilla/5.0 (compatible; IttyBittyGamingNewsBot/1.0; +https://adilo.bigcommand.com/c/ittybittygamingnews/home)"
        run: |
          python - << 'PY'
          import os, re, sys, json
          import requests

          videos_url = os.getenv("YT_VIDEOS_URL", "").strip()
          ua = os.getenv("USER_AGENT", "IttyBittyGamingNewsBot/1.0").strip()
          headers = {
              "User-Agent": ua,
              "Accept-Language": "en-US,en;q=0.9",
          }

          if not videos_url:
              print("[YT] Missing YT_VIDEOS_URL", file=sys.stderr)
              sys.exit(0)

          try:
              r = requests.get(videos_url, headers=headers, timeout=25)
              r.raise_for_status()
              html = r.text
          except Exception as e:
              print(f"[YT] Failed to fetch videos page: {e}", file=sys.stderr)
              sys.exit(0)

          # Find the first videoId on the /videos page.
          # This is usually the newest upload in the grid.
          m = re.search(r'"videoId"\s*:\s*"([A-Za-z0-9_-]{11})"', html)
          if not m:
              print("[YT] Could not find videoId in /videos HTML. Skipping YouTube auto.", file=sys.stderr)
              sys.exit(0)

          video_id = m.group(1)
          watch_url = f"https://www.youtube.com/watch?v={video_id}"

          # Get the real title via oEmbed (no API key)
          title = ""
          try:
              oembed = requests.get(
                  "https://www.youtube.com/oembed",
                  params={"url": watch_url, "format": "json"},
                  headers=headers,
                  timeout=20,
              )
              oembed.raise_for_status()
              data = oembed.json()
              title = (data.get("title") or "").strip()
          except Exception as e:
              # If oEmbed fails, fallback to a basic title regex near the first videoId.
              print(f"[YT] oEmbed failed (will fallback): {e}", file=sys.stderr)
              # This fallback isn’t perfect but better than nothing:
              # look for the first occurrence of a text title nearby.
              # Keep it safe and short.
              t = re.search(r'"title"\s*:\s*\{\s*"runs"\s*:\s*\[\s*\{\s*"text"\s*:\s*"([^"]+)"', html)
              if t:
                  title = t.group(1).strip()

          env_path = os.getenv("GITHUB_ENV")
          if not env_path:
              print("[YT] Missing GITHUB_ENV (unexpected).", file=sys.stderr)
              sys.exit(0)

          safe_title = title.replace("\n", " ").replace("\r", " ").strip()

          with open(env_path, "a", encoding="utf-8") as f:
              f.write(f"YOUTUBE_FEATURED_URL={watch_url}\n")
              f.write(f"YOUTUBE_FEATURED_TITLE={safe_title}\n")

          print(f"[YT] latest_url={watch_url}")
          print(f"[YT] latest_title={title}")
          PY

      # ---------
      # AUTO: Resolve latest Adilo upload by scraping your public "latest video" page
      # and setting FEATURED_VIDEO_FORCE_ID every run.
      # This avoids API ordering quirks and prevents home-hub fallback.
      # ---------
      - name: Resolve latest Adilo video (scrape)
        env:
          ADILO_LATEST_URL: "https://adilo.bigcommand.com/c/ittybittygamingnews/video"
          USER_AGENT: "Mozilla/5.0 (compatible; IttyBittyGamingNewsBot/1.0; +https://adilo.bigcommand.com/c/ittybittygamingnews/home)"
        run: |
          python - << 'PY'
          import os, re, sys
          import requests

          latest_url = os.getenv("ADILO_LATEST_URL", "").strip()
          ua = os.getenv("USER_AGENT", "IttyBittyGamingNewsBot/1.0").strip()
          headers = {
              "User-Agent": ua,
              "Accept-Language": "en-US,en;q=0.9",
          }

          if not latest_url:
              print("[ADILO] Missing ADILO_LATEST_URL", file=sys.stderr)
              sys.exit(0)

          try:
              r = requests.get(latest_url, headers=headers, timeout=25)
              r.raise_for_status()
              html = r.text
          except Exception as e:
              print(f"[ADILO] Failed to fetch latest page: {e}", file=sys.stderr)
              sys.exit(0)

          # Try several patterns:
          # 1) /watch/<id>
          # 2) video?id=<id>
          watch_id = None

          m1 = re.search(r'https?://adilo\.bigcommand\.com/watch/([A-Za-z0-9_-]+)', html)
          if m1:
              watch_id = m1.group(1)

          if not watch_id:
              m2 = re.search(r'video\?id=([A-Za-z0-9_-]+)', html)
              if m2:
                  watch_id = m2.group(1)

          # Sometimes the page includes JSON with an id; grab common id-ish tokens
          if not watch_id:
              m3 = re.search(r'"id"\s*:\s*"([A-Za-z0-9_-]{6,})"', html)
              if m3:
                  watch_id = m3.group(1)

          if not watch_id:
              print("[ADILO] Could not extract latest watch id from HTML. Skipping force id.", file=sys.stderr)
              sys.exit(0)

          watch_url = f"https://adilo.bigcommand.com/watch/{watch_id}"

          env_path = os.getenv("GITHUB_ENV")
          if not env_path:
              print("[ADILO] Missing GITHUB_ENV (unexpected).", file=sys.stderr)
              sys.exit(0)

          with open(env_path, "a", encoding="utf-8") as f:
              # Your digest.py already supports this and it’s the most reliable approach.
              f.write(f"FEATURED_VIDEO_FORCE_ID={watch_id}\n")
              f.write(f"FEATURED_VIDEO_FORCE_URL={watch_url}\n")

          print(f"[ADILO] latest_watch_url={watch_url}")
          PY

      - name: Run digest
        env:
          # Discord webhook for the forward-facing "content board" channel
          DISCORD_WEBHOOK_URL: ${{ secrets.CONTENT_BOARD_WEBHOOK_URL }}

          # Digest behavior
          DIGEST_WINDOW_HOURS: "24"
          DIGEST_TOP_N: "5"
          DIGEST_MAX_PER_SOURCE: "1"

          # Time guard (7pm PT) + DST handling
          DIGEST_GUARD_TZ: "America/Los_Angeles"
          DIGEST_GUARD_LOCAL_HOUR: "19"
          DIGEST_GUARD_WINDOW_MINUTES: "15"

          # Branding
          NEWSLETTER_NAME: "Itty Bitty Gaming News"
          NEWSLETTER_TAGLINE: "Snackable daily gaming news — five days a week."

          # Featured video section labels
          FEATURED_VIDEO_TITLE: "Watch today’s Itty Bitty Gaming News"
          FEATURED_VIDEO_FALLBACK_URL: "https://adilo.bigcommand.com/c/ittybittygamingnews/home"

          # Force the newest Adilo every run (set by the scrape step)
          FEATURED_VIDEO_FORCE_ID: ${{ env.FEATURED_VIDEO_FORCE_ID }}

          # Adilo API (keep these; your digest may still use them for thumbs/metadata)
          ADILO_PUBLIC_KEY: ${{ secrets.ADILO_PUBLIC_KEY }}
          ADILO_SECRET_KEY: ${{ secrets.ADILO_SECRET_KEY }}
          ADILO_PROJECT_ID: "yz8kq5M8"

          # Adilo public pages (scrape fallback)
          ADILO_PUBLIC_LATEST_PAGE: "https://adilo.bigcommand.com/c/ittybittygamingnews/video"
          ADILO_PUBLIC_HOME_PAGE: "https://adilo.bigcommand.com/c/ittybittygamingnews/home"

          # YouTube (set by the scrape step)
          YOUTUBE_FEATURED_URL: ${{ env.YOUTUBE_FEATURED_URL }}
          YOUTUBE_FEATURED_TITLE: ${{ env.YOUTUBE_FEATURED_TITLE }}

          USER_AGENT: "IttyBittyGamingNews/Digest"

        run: |
          python digest.py
