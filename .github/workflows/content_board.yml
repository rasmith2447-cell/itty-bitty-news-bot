name: Content Board (Nightly Digest)

on:
  workflow_dispatch:

  # DST-safe scheduling:
  # - 7pm PT is 03:00 UTC during PST (winter)
  # - 7pm PT is 02:00 UTC during PDT (summer)
  # Run every 10 minutes during BOTH hours; digest.py guard posts only once.
  schedule:
    - cron: "*/10 2,3 * * *"

jobs:
  post_digest:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # ---------
      # AUTO: Fetch latest YouTube upload (no API key)
      # ---------
      - name: Resolve latest YouTube video (auto)
        env:
          YT_HANDLE_URL: "https://www.youtube.com/@smitty-2447"
          USER_AGENT: "IttyBittyGamingNews/Workflow"
        run: |
          python - << 'PY'
          import os, re, sys
          import xml.etree.ElementTree as ET
          import requests

          handle_url = os.getenv("YT_HANDLE_URL", "").strip()
          ua = os.getenv("USER_AGENT", "IttyBittyGamingNews/Workflow").strip()

          if not handle_url:
            print("Missing YT_HANDLE_URL", file=sys.stderr)
            sys.exit(0)

          headers = {"User-Agent": ua}

          # 1) Fetch the handle page and extract channel id (UC...)
          try:
            r = requests.get(handle_url, headers=headers, timeout=25)
            r.raise_for_status()
            html = r.text
          except Exception as e:
            print(f"[YT] Failed to fetch handle page: {e}", file=sys.stderr)
            sys.exit(0)

          # Common patterns where channel id appears
          patterns = [
            r'"channelId"\s*:\s*"(?P<id>UC[a-zA-Z0-9_-]{10,})"',
            r'"browseId"\s*:\s*"(?P<id>UC[a-zA-Z0-9_-]{10,})"',
            r'<meta\s+property="og:url"\s+content="https://www\.youtube\.com/channel/(?P<id>UC[a-zA-Z0-9_-]{10,})"',
            r'https://www\.youtube\.com/channel/(?P<id>UC[a-zA-Z0-9_-]{10,})',
          ]

          channel_id = None
          for pat in patterns:
            m = re.search(pat, html)
            if m:
              channel_id = m.group("id")
              break

          if not channel_id:
            print("[YT] Could not extract channel id from handle page HTML. Skipping YouTube auto.", file=sys.stderr)
            sys.exit(0)

          print(f"[YT] channel_id={channel_id}")

          # 2) Pull latest upload from RSS
          rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
          try:
            rr = requests.get(rss_url, headers=headers, timeout=25)
            rr.raise_for_status()
            xml_text = rr.text
          except Exception as e:
            print(f"[YT] Failed to fetch RSS: {e}", file=sys.stderr)
            sys.exit(0)

          try:
            root = ET.fromstring(xml_text)
          except Exception as e:
            print(f"[YT] RSS parse failed: {e}", file=sys.stderr)
            sys.exit(0)

          ns = {"a": "http://www.w3.org/2005/Atom"}
          entry = root.find("a:entry", ns)
          if entry is None:
            print("[YT] RSS had no entries. Skipping YouTube auto.", file=sys.stderr)
            sys.exit(0)

          title_el = entry.find("a:title", ns)
          link_el = entry.find("a:link", ns)
          title = (title_el.text or "").strip() if title_el is not None else ""
          href = (link_el.attrib.get("href") or "").strip() if link_el is not None else ""

          if not href:
            print("[YT] RSS entry missing link href. Skipping YouTube auto.", file=sys.stderr)
            sys.exit(0)

          # Write values into GITHUB_ENV for downstream steps
          env_path = os.getenv("GITHUB_ENV")
          if not env_path:
            print("[YT] Missing GITHUB_ENV (unexpected).", file=sys.stderr)
            sys.exit(0)

          with open(env_path, "a", encoding="utf-8") as f:
            f.write(f"YOUTUBE_FEATURED_URL={href}\n")
            # Avoid breaking env file with newlines
            safe_title = title.replace("\n", " ").replace("\r", " ").strip()
            f.write(f"YOUTUBE_FEATURED_TITLE={safe_title}\n")

          print(f"[YT] latest_url={href}")
          print(f"[YT] latest_title={title}")
          PY

      - name: Run digest
        env:
          # Discord webhook for the forward-facing "content board" channel
          DISCORD_WEBHOOK_URL: ${{ secrets.CONTENT_BOARD_WEBHOOK_URL }}

          # Digest behavior
          DIGEST_WINDOW_HOURS: "24"
          DIGEST_TOP_N: "5"
          DIGEST_MAX_PER_SOURCE: "1"

          # Time guard (7pm PT) + DST handling
          DIGEST_GUARD_TZ: "America/Los_Angeles"
          DIGEST_GUARD_LOCAL_HOUR: "19"
          DIGEST_GUARD_WINDOW_MINUTES: "15"

          # Branding
          NEWSLETTER_NAME: "Itty Bitty Gaming News"
          NEWSLETTER_TAGLINE: "Snackable daily gaming news — five days a week."

          # Featured video section labels
          FEATURED_VIDEO_TITLE: "Watch today’s Itty Bitty Gaming News"
          FEATURED_VIDEO_FALLBACK_URL: "https://adilo.bigcommand.com/c/ittybittygamingnews/home"

          # Adilo API
          ADILO_PUBLIC_KEY: ${{ secrets.ADILO_PUBLIC_KEY }}
          ADILO_SECRET_KEY: ${{ secrets.ADILO_SECRET_KEY }}
          ADILO_PROJECT_ID: "yz8kq5M8"

          # Adilo public pages (scrape fallback)
          ADILO_PUBLIC_LATEST_PAGE: "https://adilo.bigcommand.com/c/ittybittygamingnews/video"
          ADILO_PUBLIC_HOME_PAGE: "https://adilo.bigcommand.com/c/ittybittygamingnews/home"

          # YouTube values are set automatically by the previous step into GITHUB_ENV
          # and will be available here as environment variables.
          YOUTUBE_FEATURED_URL: ${{ env.YOUTUBE_FEATURED_URL }}
          YOUTUBE_FEATURED_TITLE: ${{ env.YOUTUBE_FEATURED_TITLE }}

          # User-Agent (polite scraping + debugging clarity)
          USER_AGENT: "IttyBittyGamingNews/Digest"

        run: |
          python digest.py
